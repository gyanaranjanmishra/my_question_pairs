{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IJMNmFX-tn11"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "koooWOm0wpCJ"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "m_bNILvow5Xb",
    "outputId": "d947cea4-4a6d-4c17-f0c9-8314e0d429b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 6)\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "I2LO9nmbw-du"
   },
   "outputs": [],
   "source": [
    "def preprocess(q):\n",
    "\n",
    "    q = str(q).lower().strip()\n",
    "\n",
    "    # Replace certain special characters with their string equivalents\n",
    "    q = q.replace('%', ' percent')\n",
    "    q = q.replace('$', ' dollar ')\n",
    "    q = q.replace('₹', ' rupee ')\n",
    "    q = q.replace('€', ' euro ')\n",
    "    q = q.replace('@', ' at ')\n",
    "\n",
    "    # The pattern '[math]' appears around 900 times in the whole dataset.\n",
    "    q = q.replace('[math]', '')\n",
    "\n",
    "    # Replacing some numbers with string equivalents (not perfect, can be done better to account for more cases)\n",
    "    q = q.replace(',000,000,000 ', 'b ')\n",
    "    q = q.replace(',000,000 ', 'm ')\n",
    "    q = q.replace(',000 ', 'k ')\n",
    "    q = re.sub(r'([0-9]+)000000000', r'\\1b', q)\n",
    "    q = re.sub(r'([0-9]+)000000', r'\\1m', q)\n",
    "    q = re.sub(r'([0-9]+)000', r'\\1k', q)\n",
    "\n",
    "    # Decontracting words\n",
    "    # https://en.wikipedia.org/wiki/Wikipedia%3aList_of_English_contractions\n",
    "    # https://stackoverflow.com/a/19794953\n",
    "    contractions = {\n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"can't've\": \"can not have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he will have\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'll've\": \"i will have\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so as\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'll've\": \"who will have\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "    }\n",
    "\n",
    "    q_decontracted = []\n",
    "\n",
    "    for word in q.split():\n",
    "        if word in contractions:\n",
    "            word = contractions[word]\n",
    "\n",
    "        q_decontracted.append(word)\n",
    "\n",
    "    q = ' '.join(q_decontracted)\n",
    "    q = q.replace(\"'ve\", \" have\")\n",
    "    q = q.replace(\"n't\", \" not\")\n",
    "    q = q.replace(\"'re\", \" are\")\n",
    "    q = q.replace(\"'ll\", \" will\")\n",
    "\n",
    "    # Removing HTML tags\n",
    "    q = BeautifulSoup(q)\n",
    "    q = q.get_text()\n",
    "\n",
    "    # Remove punctuations\n",
    "    pattern = re.compile('\\W')\n",
    "    q = re.sub(pattern, ' ', q).strip()\n",
    "\n",
    "\n",
    "    return q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['question1'] = df['question1'].apply(preprocess)\n",
    "df['question2'] = df['question2'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JPQZ0ju1xHSc"
   },
   "outputs": [],
   "source": [
    "df['q1_len'] = df['question1'].str.len()\n",
    "df['q2_len'] = df['question2'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cuL7eUGdxdwa"
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643
    },
    "id": "UB5eUFtMxQ4u",
    "outputId": "7efb39da-c91e-4f3c-f3a0-133d76caec03"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_num_words</th>\n",
       "      <th>q2_num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>56</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor  koh i noor  dia...</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>87</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>58</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am i mentally very lonely  how can i solve it</td>\n",
       "      <td>find the remainder when 23  24   math  is divi...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>58</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar  salt...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  what is the step by step guide to invest in sh...   \n",
       "1   1     3     4  what is the story of kohinoor  koh i noor  dia...   \n",
       "2   2     5     6  how can i increase the speed of my internet co...   \n",
       "3   3     7     8  why am i mentally very lonely  how can i solve it   \n",
       "4   4     9    10  which one dissolve in water quikly sugar  salt...   \n",
       "\n",
       "                                           question2  is_duplicate  q1_len  \\\n",
       "0  what is the step by step guide to invest in sh...             0      65   \n",
       "1  what would happen if the indian government sto...             0      50   \n",
       "2  how can internet speed be increased by hacking...             0      72   \n",
       "3  find the remainder when 23  24   math  is divi...             0      49   \n",
       "4             which fish would survive in salt water             0      75   \n",
       "\n",
       "   q2_len  q1_num_words  q2_num_words  \n",
       "0      56            14            12  \n",
       "1      87            12            17  \n",
       "2      58            14            10  \n",
       "3      58            12            16  \n",
       "4      38            15             7  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['q1_num_words'] = df['question1'].apply(lambda x: len(x.split(\" \")))\n",
    "df['q2_num_words'] = df['question2'].apply(lambda x: len(x.split(\" \")))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643
    },
    "id": "qh87UeTQylPZ",
    "outputId": "0b6c7a8e-cfae-407d-9a52-9696e8374d1d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_num_words</th>\n",
       "      <th>q2_num_words</th>\n",
       "      <th>word_common</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>56</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor  koh i noor  dia...</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>87</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>58</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am i mentally very lonely  how can i solve it</td>\n",
       "      <td>find the remainder when 23  24   math  is divi...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>58</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar  salt...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  what is the step by step guide to invest in sh...   \n",
       "1   1     3     4  what is the story of kohinoor  koh i noor  dia...   \n",
       "2   2     5     6  how can i increase the speed of my internet co...   \n",
       "3   3     7     8  why am i mentally very lonely  how can i solve it   \n",
       "4   4     9    10  which one dissolve in water quikly sugar  salt...   \n",
       "\n",
       "                                           question2  is_duplicate  q1_len  \\\n",
       "0  what is the step by step guide to invest in sh...             0      65   \n",
       "1  what would happen if the indian government sto...             0      50   \n",
       "2  how can internet speed be increased by hacking...             0      72   \n",
       "3  find the remainder when 23  24   math  is divi...             0      49   \n",
       "4             which fish would survive in salt water             0      75   \n",
       "\n",
       "   q2_len  q1_num_words  q2_num_words  word_common  \n",
       "0      56            14            12           11  \n",
       "1      87            12            17            8  \n",
       "2      58            14            10            4  \n",
       "3      58            12            16            1  \n",
       "4      38            15             7            4  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def common_words(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))\n",
    "    return len(w1 & w2)\n",
    "\n",
    "\n",
    "df['word_common'] = df.apply(common_words, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "S0Myx7gRyy0w"
   },
   "outputs": [],
   "source": [
    "def total_words(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))\n",
    "    return (len(w1) + len(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643
    },
    "id": "Nr0K6pcjzD74",
    "outputId": "d6c58c77-b421-4d24-91f7-ea9d7bd0b627"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_num_words</th>\n",
       "      <th>q2_num_words</th>\n",
       "      <th>word_common</th>\n",
       "      <th>word_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>56</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor  koh i noor  dia...</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>87</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>58</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am i mentally very lonely  how can i solve it</td>\n",
       "      <td>find the remainder when 23  24   math  is divi...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>58</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar  salt...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  what is the step by step guide to invest in sh...   \n",
       "1   1     3     4  what is the story of kohinoor  koh i noor  dia...   \n",
       "2   2     5     6  how can i increase the speed of my internet co...   \n",
       "3   3     7     8  why am i mentally very lonely  how can i solve it   \n",
       "4   4     9    10  which one dissolve in water quikly sugar  salt...   \n",
       "\n",
       "                                           question2  is_duplicate  q1_len  \\\n",
       "0  what is the step by step guide to invest in sh...             0      65   \n",
       "1  what would happen if the indian government sto...             0      50   \n",
       "2  how can internet speed be increased by hacking...             0      72   \n",
       "3  find the remainder when 23  24   math  is divi...             0      49   \n",
       "4             which fish would survive in salt water             0      75   \n",
       "\n",
       "   q2_len  q1_num_words  q2_num_words  word_common  word_total  \n",
       "0      56            14            12           11          23  \n",
       "1      87            12            17            8          26  \n",
       "2      58            14            10            4          24  \n",
       "3      58            12            16            1          22  \n",
       "4      38            15             7            4          21  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word_total'] = df.apply(total_words, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "YB8kpfXVzNEF",
    "outputId": "95c9646d-bbd5-402b-9d6b-1f92de1e671b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_num_words</th>\n",
       "      <th>q2_num_words</th>\n",
       "      <th>word_common</th>\n",
       "      <th>word_total</th>\n",
       "      <th>word_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, qid1, qid2, question1, question2, is_duplicate, q1_len, q2_len, q1_num_words, q2_num_words, word_common, word_total, word_share]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word_share'] = round(df['word_common']/df['word_total'],2)\n",
    "df.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "tUr0aWtVzQ74"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "r_s9XuiBzboQ"
   },
   "outputs": [],
   "source": [
    "def fetch_token_features(row):\n",
    "\n",
    "    q1 = row['question1']\n",
    "    q2 = row['question2']\n",
    "\n",
    "    SAFE_DIV = 0.0001\n",
    "\n",
    "    STOP_WORDS = stopwords.words(\"english\")\n",
    "\n",
    "    token_features = [0.0]*8\n",
    "\n",
    "    # Converting the Sentence into Tokens:\n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "\n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return token_features\n",
    "\n",
    "    # Get the non-stopwords in Questions\n",
    "    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n",
    "    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n",
    "\n",
    "    #Get the stopwords in Questions\n",
    "    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n",
    "    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n",
    "\n",
    "    # Get the common non-stopwords from Question pair\n",
    "    common_word_count = len(q1_words.intersection(q2_words))\n",
    "\n",
    "    # Get the common stopwords from Question pair\n",
    "    common_stop_count = len(q1_stops.intersection(q2_stops))\n",
    "\n",
    "    # Get the common Tokens from Question pair\n",
    "    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
    "\n",
    "\n",
    "    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "\n",
    "    # Last word of both question is same or not\n",
    "    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
    "\n",
    "    # First word of both question is same or not\n",
    "    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n",
    "\n",
    "    return token_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "g7Bx2uPqzirI"
   },
   "outputs": [],
   "source": [
    "token_features = df.apply(fetch_token_features, axis=1)\n",
    "\n",
    "df[\"cwc_min\"]       = list(map(lambda x: x[0], token_features))\n",
    "df[\"cwc_max\"]       = list(map(lambda x: x[1], token_features))\n",
    "df[\"csc_min\"]       = list(map(lambda x: x[2], token_features))\n",
    "df[\"csc_max\"]       = list(map(lambda x: x[3], token_features))\n",
    "df[\"ctc_min\"]       = list(map(lambda x: x[4], token_features))\n",
    "df[\"ctc_max\"]       = list(map(lambda x: x[5], token_features))\n",
    "df[\"last_word_eq\"]  = list(map(lambda x: x[6], token_features))\n",
    "df[\"first_word_eq\"] = list(map(lambda x: x[7], token_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4AAmeevx2RAk"
   },
   "outputs": [],
   "source": [
    "import distance\n",
    "q1=\"capital of india is delhi\"\n",
    "q2 = \"capital of india is xyz\"\n",
    "\n",
    "trial = list(distance.lcsubstrings(q1, q2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ZXwWeo5L2htU",
    "outputId": "812ebc83-9074-4adc-8946-67645569da54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'capital of india is '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Dksqhftd0suK"
   },
   "outputs": [],
   "source": [
    "import distance\n",
    "\n",
    "def fetch_length_features(row):\n",
    "\n",
    "    q1 = row['question1']\n",
    "    q2 = row['question2']\n",
    "\n",
    "    length_features = [0.0]*3\n",
    "\n",
    "    # Converting the Sentence into Tokens:\n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "\n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return length_features\n",
    "\n",
    "    # Absolute length features\n",
    "    length_features[0] = abs(len(q1_tokens) - len(q2_tokens))\n",
    "\n",
    "    #Average Token Length of both Questions\n",
    "    length_features[1] = (len(q1_tokens) + len(q2_tokens))/2\n",
    "\n",
    "    strs = list(distance.lcsubstrings(q1, q2))\n",
    "    if len(strs) > 0:\n",
    "        length_features[2] = len(strs[0]) / (min(len(q1), len(q2)) + 1)\n",
    "    else:\n",
    "        length_features[2] = 0.0 # Handle cases where no common substring is found\n",
    "\n",
    "    return length_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "VZ9vC2Q_1H1m"
   },
   "outputs": [],
   "source": [
    "\n",
    "length_features = df.apply(fetch_length_features, axis=1)\n",
    "\n",
    "df['abs_len_diff'] = list(map(lambda x: x[0], length_features))\n",
    "df['mean_len'] = list(map(lambda x: x[1], length_features))\n",
    "df['longest_substr_ratio'] = list(map(lambda x: x[2], length_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZRNZtndd4JGS",
    "outputId": "99505bf2-bf68-43d0-bab9-fd40b9aca444"
   },
   "outputs": [],
   "source": [
    "#pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "CNfyK_Ld4NRR"
   },
   "outputs": [],
   "source": [
    "# Fuzzy Features\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def fetch_fuzzy_features(row):\n",
    "\n",
    "    q1 = row['question1']\n",
    "    q2 = row['question2']\n",
    "\n",
    "    fuzzy_features = [0.0]*4\n",
    "\n",
    "    # fuzz_ratio\n",
    "    fuzzy_features[0] = fuzz.QRatio(q1, q2)\n",
    "\n",
    "    # fuzz_partial_ratio\n",
    "    fuzzy_features[1] = fuzz.partial_ratio(q1, q2)\n",
    "\n",
    "    # token_sort_ratio\n",
    "    fuzzy_features[2] = fuzz.token_sort_ratio(q1, q2)\n",
    "\n",
    "    # token_set_ratio\n",
    "    fuzzy_features[3] = fuzz.token_set_ratio(q1, q2)\n",
    "\n",
    "    return fuzzy_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "pJ20COJH4QjW"
   },
   "outputs": [],
   "source": [
    "fuzzy_features = df.apply(fetch_fuzzy_features, axis=1)\n",
    "\n",
    "# Creating new feature columns for fuzzy features\n",
    "df['fuzz_ratio'] = list(map(lambda x: x[0], fuzzy_features))\n",
    "df['fuzz_partial_ratio'] = list(map(lambda x: x[1], fuzzy_features))\n",
    "df['token_sort_ratio'] = list(map(lambda x: x[2], fuzzy_features))\n",
    "df['token_set_ratio'] = list(map(lambda x: x[3], fuzzy_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AL3RdIvB8aD5",
    "outputId": "ef5bdd5e-d916-4a57-8366-39ebde483c78"
   },
   "outputs": [],
   "source": [
    "#pip show gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TW-HlVfv8hMl",
    "outputId": "d550059c-03a4-4006-c5f9-3e8e5b6a76cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 28)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "H8k6QwCP82yC",
    "outputId": "00c5ccc7-1b21-48f9-a526-6d8d392212c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is the story of kohinoor  koh i noor  dia...</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>why am i mentally very lonely  how can i solve it</td>\n",
       "      <td>find the remainder when 23  24   math  is divi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>which one dissolve in water quikly sugar  salt...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  what is the step by step guide to invest in sh...   \n",
       "1  what is the story of kohinoor  koh i noor  dia...   \n",
       "2  how can i increase the speed of my internet co...   \n",
       "3  why am i mentally very lonely  how can i solve it   \n",
       "4  which one dissolve in water quikly sugar  salt...   \n",
       "\n",
       "                                           question2  \n",
       "0  what is the step by step guide to invest in sh...  \n",
       "1  what would happen if the indian government sto...  \n",
       "2  how can internet speed be increased by hacking...  \n",
       "3  find the remainder when 23  24   math  is divi...  \n",
       "4             which fish would survive in salt water  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ques_df = df[['question1','question2']]\n",
    "ques_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "DiCqk5Og9E9r",
    "outputId": "7b21a39f-3829-48d6-9c71-25510e02a776"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_num_words</th>\n",
       "      <th>q2_num_words</th>\n",
       "      <th>word_common</th>\n",
       "      <th>word_total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>...</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>token_set_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>56</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>87</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>66</td>\n",
       "      <td>74</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>58</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.169492</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>58</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>35</td>\n",
       "      <td>55</td>\n",
       "      <td>47</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_duplicate  q1_len  q2_len  q1_num_words  q2_num_words  word_common  \\\n",
       "0             0      65      56            14            12           11   \n",
       "1             0      50      87            12            17            8   \n",
       "2             0      72      58            14            10            4   \n",
       "3             0      49      58            12            16            1   \n",
       "4             0      75      38            15             7            4   \n",
       "\n",
       "   word_total  word_share   cwc_min   cwc_max  ...   ctc_max  last_word_eq  \\\n",
       "0          23        0.48  0.999980  0.833319  ...  0.785709           0.0   \n",
       "1          26        0.31  0.799984  0.399996  ...  0.466664           0.0   \n",
       "2          24        0.17  0.399992  0.333328  ...  0.285712           0.0   \n",
       "3          22        0.05  0.000000  0.000000  ...  0.000000           0.0   \n",
       "4          21        0.19  0.399992  0.199998  ...  0.307690           0.0   \n",
       "\n",
       "   first_word_eq  abs_len_diff  mean_len  longest_substr_ratio  fuzz_ratio  \\\n",
       "0            1.0           2.0      13.0              0.982456          93   \n",
       "1            1.0           5.0      12.5              0.588235          66   \n",
       "2            1.0           4.0      12.0              0.169492          43   \n",
       "3            0.0           1.0      11.5              0.040000           9   \n",
       "4            1.0           6.0      10.0              0.153846          35   \n",
       "\n",
       "   fuzz_partial_ratio  token_sort_ratio  token_set_ratio  \n",
       "0                 100                93              100  \n",
       "1                  74                63               86  \n",
       "2                  46                63               63  \n",
       "3                  11                25               28  \n",
       "4                  55                47               67  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = df.drop(columns=['id','qid1','qid2','question1','question2'])\n",
    "print(final_df.shape)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "IyD2GwkW9lsb"
   },
   "outputs": [],
   "source": [
    "questions = list(ques_df['question1']) + list(ques_df['question2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UzhWDCJT-EES",
    "outputId": "eb5accca-73d4-4f35-ca40-30328c5a44d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808580"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "j9kWIwFN-HG3"
   },
   "outputs": [],
   "source": [
    "import gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#nltk.download(\"punkt\")\n",
    "#nltk.download(\"stopwords\")\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess2(text):\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "processed_questions = [preprocess2(text) for text in questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808580"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    }
   ],
   "source": [
    "modelword2vec = gensim.models.Word2Vec(\n",
    "    sentences=processed_questions,\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=8,\n",
    "    vector_size=300,\n",
    "    epochs= 10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    }
   ],
   "source": [
    "modelfasttext = gensim.models.FastText(\n",
    "    sentences=processed_questions,\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=8,\n",
    "    vector_size=100,\n",
    "    epochs= 10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def sentence_vector(, model, size=modelword2vec.vector_size):\n",
    "    vectors = []\n",
    "    \n",
    "    for word in tokens:\n",
    "        if word in model.wv:\n",
    "            vectors.append(model.wv[word])\n",
    "    \n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(vector_size)\n",
    "    \n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "\n",
    "# Generate vectors for each question\n",
    "question_vectors = [\n",
    "    sentence_vector(q, modelword2vec, 300)\n",
    "    for q in processed_questions\n",
    "]\n",
    "\n",
    "# Convert to NumPy array (feature matrix)\n",
    "q1_arr, q2_arr = np.vsplit(np.array(question_vectors),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sentence_columns(row1, row2, model, size=300):\n",
    "\n",
    "    row1_tokens = preprocess2(row1)\n",
    "    row2_tokens = preprocess2(row2)\n",
    "\n",
    "    def tokens_to_vec(tokens):\n",
    "\n",
    "        vecs = []\n",
    "\n",
    "        for w in tokens:\n",
    "            if w in model.wv:   # check first\n",
    "                vecs.append(model.wv[w])\n",
    "\n",
    "        if len(vecs) == 0:\n",
    "            return np.zeros(size)\n",
    "\n",
    "        return np.mean(vecs, axis=0)\n",
    "\n",
    "    \n",
    "    q1_vec = tokens_to_vec(row1_tokens)\n",
    "    q2_vec = tokens_to_vec(row2_tokens)\n",
    "\n",
    "    return q1_vec, q2_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.56540394,  0.16368648, -0.6144675 ,  0.02467153,  0.54140073,\n",
       "         0.79463434,  0.56056607, -0.27509427, -0.1269512 ,  0.5458004 ,\n",
       "        -0.5075064 ,  0.7658272 ,  0.42526415,  0.8147581 , -0.05024844,\n",
       "         0.67047465, -0.19551694,  0.784603  ,  0.17572124,  0.8724292 ,\n",
       "         1.0286224 , -0.5111665 ,  0.5142372 , -1.0364633 ,  0.8376356 ,\n",
       "        -0.00433811,  1.0722911 , -0.21723412, -0.06910495,  0.15736218,\n",
       "        -0.11028348, -0.29872957,  0.11958271,  0.57942104, -0.52494276,\n",
       "         0.10818131,  0.1904482 , -0.32996628,  0.10508294,  0.05578801,\n",
       "        -0.41487318, -0.4005811 ,  0.99131787,  0.65862465,  0.08563539,\n",
       "         0.4142579 ,  0.13146837, -0.06372965, -0.10339459, -0.3565744 ,\n",
       "        -0.0744526 ,  0.00965117, -0.2893245 , -0.4638772 ,  0.17588301,\n",
       "        -0.04605129,  0.46562973, -0.21936855,  0.02453278, -0.03504988,\n",
       "         0.26983926,  0.36155647,  0.9682738 ,  0.10246575, -0.21034004,\n",
       "         0.71905154, -0.27869856,  0.3615361 ,  0.42691615,  0.35197034,\n",
       "         0.260402  , -0.15862541,  0.14377022,  0.57649136,  0.21077664,\n",
       "        -0.83542264, -0.03359703,  0.28912255, -0.05056481,  0.15290461,\n",
       "        -0.6557326 , -0.38229704,  0.01259103, -0.2585722 ,  0.01897349,\n",
       "        -0.08939589, -0.1932749 ,  0.27451435, -0.07418847, -0.4901995 ,\n",
       "         0.4657072 ,  0.46156064, -1.0073526 ,  0.51391184, -0.33300528,\n",
       "         0.15949352,  0.25302452, -0.16281731,  0.02362365,  0.59142053,\n",
       "         0.570697  , -0.1677369 , -0.5871854 ,  1.1950027 , -0.03821698,\n",
       "         0.06715523, -0.27105168, -0.47051668, -0.3149782 , -0.5181075 ,\n",
       "         0.10333576, -0.02950176, -0.2670622 , -0.39528844, -0.21392652,\n",
       "        -0.52856094,  0.32934174, -1.0370947 , -0.60803443,  0.11495972,\n",
       "         0.2733054 , -0.46778712, -0.0385586 , -0.5287501 ,  0.01859766,\n",
       "        -0.6551979 ,  0.1560999 , -0.05640837,  0.12110683,  0.21244599,\n",
       "        -0.7542377 ,  0.34424973, -0.22333118, -0.3804582 , -0.27317697,\n",
       "        -0.79672706, -0.60442066,  0.23727581,  0.13772884, -0.47552916,\n",
       "         0.02779318,  0.2654526 ,  0.8120287 ,  0.866841  , -0.46275648,\n",
       "        -0.05225068,  0.46544355, -0.19597824,  0.12695909,  0.92539406,\n",
       "        -0.44985294, -0.69673455,  1.3586105 , -0.5223216 ,  0.00895748,\n",
       "         0.82366496,  0.01689216,  0.11270986,  0.6638035 ,  0.3143582 ,\n",
       "         0.15763175, -0.2449894 ,  0.3340044 , -0.6663576 , -0.77521294,\n",
       "        -0.4050035 ,  0.52536994,  0.19372095, -0.08263491,  0.2814648 ,\n",
       "        -0.7934619 , -0.66738695,  0.74733984, -0.38445446, -0.7081102 ,\n",
       "         0.2801641 ,  0.646179  , -0.16275318, -1.4078571 , -0.38181517,\n",
       "         0.45026308,  0.49658564,  0.18936928, -0.49796227, -0.3086709 ,\n",
       "        -0.4166096 , -0.8119073 , -0.42946744, -0.07877503, -0.7002717 ,\n",
       "        -0.4243094 , -0.30441192,  0.3688912 ,  0.44121602, -0.6678233 ,\n",
       "         0.8742129 , -0.14857379,  0.32062605, -0.24282588, -0.58990145,\n",
       "        -0.21372768, -0.5204967 ,  0.1224675 ,  0.41505903, -0.16100977,\n",
       "        -0.3035814 , -0.08262545,  0.81544006, -0.41380367,  0.25964692,\n",
       "         0.2283552 ,  0.03403227,  1.0310788 ,  0.4692244 , -0.38438755,\n",
       "        -0.23623228, -0.6738537 ,  0.7032084 ,  0.07114231,  0.6372766 ,\n",
       "        -0.39296415,  0.32569566, -1.0192894 , -0.18569852, -0.30732012,\n",
       "         0.6292457 , -0.35414606, -1.316501  , -0.12156202, -0.12859109,\n",
       "        -0.24045385,  0.4821826 , -0.12102944,  0.75045156, -0.18366908,\n",
       "        -0.48416415,  0.22716519,  0.0893046 ,  0.33690187, -0.31949487,\n",
       "         0.20020914,  0.19837572, -0.02889993, -0.29549122,  0.21768431,\n",
       "         0.01247093, -0.5637814 ,  0.00997452, -0.2920074 ,  0.28987625,\n",
       "        -0.35714954, -0.67702293, -0.9251032 , -0.3152072 , -0.07601883,\n",
       "         0.22805092, -0.5407573 , -0.37982136, -0.6284665 ,  0.71012074,\n",
       "         0.6407766 ,  0.5978466 ,  0.35205597, -0.04208315, -1.0164536 ,\n",
       "        -0.92952645, -0.6828862 , -0.3173337 ,  0.7389054 , -1.1679028 ,\n",
       "         0.2591937 ,  0.3094341 , -0.02355103, -0.13663211, -0.67059165,\n",
       "        -0.4800207 , -0.00817501, -0.5436316 , -0.17785321,  0.05838631,\n",
       "        -0.32378504, -0.86394817,  0.6755277 , -0.07850271,  0.34637812,\n",
       "        -0.36598653,  0.31944224,  0.02733474,  0.1291072 ,  0.07381405,\n",
       "        -0.1270914 , -0.19345796, -0.5569891 , -0.756579  , -1.074418  ,\n",
       "         0.03068862,  0.35074553,  0.9836951 , -0.29609606,  0.44279593],\n",
       "       dtype=float32),\n",
       " array([ 0.56540394,  0.16368648, -0.6144675 ,  0.02467153,  0.54140073,\n",
       "         0.79463434,  0.56056607, -0.27509427, -0.1269512 ,  0.5458004 ,\n",
       "        -0.5075064 ,  0.7658272 ,  0.42526415,  0.8147581 , -0.05024844,\n",
       "         0.67047465, -0.19551694,  0.784603  ,  0.17572124,  0.8724292 ,\n",
       "         1.0286224 , -0.5111665 ,  0.5142372 , -1.0364633 ,  0.8376356 ,\n",
       "        -0.00433811,  1.0722911 , -0.21723412, -0.06910495,  0.15736218,\n",
       "        -0.11028348, -0.29872957,  0.11958271,  0.57942104, -0.52494276,\n",
       "         0.10818131,  0.1904482 , -0.32996628,  0.10508294,  0.05578801,\n",
       "        -0.41487318, -0.4005811 ,  0.99131787,  0.65862465,  0.08563539,\n",
       "         0.4142579 ,  0.13146837, -0.06372965, -0.10339459, -0.3565744 ,\n",
       "        -0.0744526 ,  0.00965117, -0.2893245 , -0.4638772 ,  0.17588301,\n",
       "        -0.04605129,  0.46562973, -0.21936855,  0.02453278, -0.03504988,\n",
       "         0.26983926,  0.36155647,  0.9682738 ,  0.10246575, -0.21034004,\n",
       "         0.71905154, -0.27869856,  0.3615361 ,  0.42691615,  0.35197034,\n",
       "         0.260402  , -0.15862541,  0.14377022,  0.57649136,  0.21077664,\n",
       "        -0.83542264, -0.03359703,  0.28912255, -0.05056481,  0.15290461,\n",
       "        -0.6557326 , -0.38229704,  0.01259103, -0.2585722 ,  0.01897349,\n",
       "        -0.08939589, -0.1932749 ,  0.27451435, -0.07418847, -0.4901995 ,\n",
       "         0.4657072 ,  0.46156064, -1.0073526 ,  0.51391184, -0.33300528,\n",
       "         0.15949352,  0.25302452, -0.16281731,  0.02362365,  0.59142053,\n",
       "         0.570697  , -0.1677369 , -0.5871854 ,  1.1950027 , -0.03821698,\n",
       "         0.06715523, -0.27105168, -0.47051668, -0.3149782 , -0.5181075 ,\n",
       "         0.10333576, -0.02950176, -0.2670622 , -0.39528844, -0.21392652,\n",
       "        -0.52856094,  0.32934174, -1.0370947 , -0.60803443,  0.11495972,\n",
       "         0.2733054 , -0.46778712, -0.0385586 , -0.5287501 ,  0.01859766,\n",
       "        -0.6551979 ,  0.1560999 , -0.05640837,  0.12110683,  0.21244599,\n",
       "        -0.7542377 ,  0.34424973, -0.22333118, -0.3804582 , -0.27317697,\n",
       "        -0.79672706, -0.60442066,  0.23727581,  0.13772884, -0.47552916,\n",
       "         0.02779318,  0.2654526 ,  0.8120287 ,  0.866841  , -0.46275648,\n",
       "        -0.05225068,  0.46544355, -0.19597824,  0.12695909,  0.92539406,\n",
       "        -0.44985294, -0.69673455,  1.3586105 , -0.5223216 ,  0.00895748,\n",
       "         0.82366496,  0.01689216,  0.11270986,  0.6638035 ,  0.3143582 ,\n",
       "         0.15763175, -0.2449894 ,  0.3340044 , -0.6663576 , -0.77521294,\n",
       "        -0.4050035 ,  0.52536994,  0.19372095, -0.08263491,  0.2814648 ,\n",
       "        -0.7934619 , -0.66738695,  0.74733984, -0.38445446, -0.7081102 ,\n",
       "         0.2801641 ,  0.646179  , -0.16275318, -1.4078571 , -0.38181517,\n",
       "         0.45026308,  0.49658564,  0.18936928, -0.49796227, -0.3086709 ,\n",
       "        -0.4166096 , -0.8119073 , -0.42946744, -0.07877503, -0.7002717 ,\n",
       "        -0.4243094 , -0.30441192,  0.3688912 ,  0.44121602, -0.6678233 ,\n",
       "         0.8742129 , -0.14857379,  0.32062605, -0.24282588, -0.58990145,\n",
       "        -0.21372768, -0.5204967 ,  0.1224675 ,  0.41505903, -0.16100977,\n",
       "        -0.3035814 , -0.08262545,  0.81544006, -0.41380367,  0.25964692,\n",
       "         0.2283552 ,  0.03403227,  1.0310788 ,  0.4692244 , -0.38438755,\n",
       "        -0.23623228, -0.6738537 ,  0.7032084 ,  0.07114231,  0.6372766 ,\n",
       "        -0.39296415,  0.32569566, -1.0192894 , -0.18569852, -0.30732012,\n",
       "         0.6292457 , -0.35414606, -1.316501  , -0.12156202, -0.12859109,\n",
       "        -0.24045385,  0.4821826 , -0.12102944,  0.75045156, -0.18366908,\n",
       "        -0.48416415,  0.22716519,  0.0893046 ,  0.33690187, -0.31949487,\n",
       "         0.20020914,  0.19837572, -0.02889993, -0.29549122,  0.21768431,\n",
       "         0.01247093, -0.5637814 ,  0.00997452, -0.2920074 ,  0.28987625,\n",
       "        -0.35714954, -0.67702293, -0.9251032 , -0.3152072 , -0.07601883,\n",
       "         0.22805092, -0.5407573 , -0.37982136, -0.6284665 ,  0.71012074,\n",
       "         0.6407766 ,  0.5978466 ,  0.35205597, -0.04208315, -1.0164536 ,\n",
       "        -0.92952645, -0.6828862 , -0.3173337 ,  0.7389054 , -1.1679028 ,\n",
       "         0.2591937 ,  0.3094341 , -0.02355103, -0.13663211, -0.67059165,\n",
       "        -0.4800207 , -0.00817501, -0.5436316 , -0.17785321,  0.05838631,\n",
       "        -0.32378504, -0.86394817,  0.6755277 , -0.07850271,  0.34637812,\n",
       "        -0.36598653,  0.31944224,  0.02733474,  0.1291072 ,  0.07381405,\n",
       "        -0.1270914 , -0.19345796, -0.5569891 , -0.756579  , -1.074418  ,\n",
       "         0.03068862,  0.35074553,  0.9836951 , -0.29609606,  0.44279593],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_sentence_columns(ques_df['question1'][0],ques_df['question1'][0],modelword2vec,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=final_df.iloc[:,0:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors= df.apply(\n",
    "    lambda row: vectorize_sentence_columns(\n",
    "        row[\"question1\"],\n",
    "        row[\"question2\"],\n",
    "        modelword2vec,\n",
    "        size=300\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "q1_vecs = vectors.apply(lambda x: x[0])\n",
    "q2_vecs = vectors.apply(lambda x: x[1])\n",
    "\n",
    "q1_df = pd.DataFrame(q1_vecs.tolist(), index=df.index)\n",
    "q2_df = pd.DataFrame(q2_vecs.tolist(), index=df.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 600)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.concat([q1_df, q2_df], axis=1)\n",
    "temp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 23)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 623)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_num_words</th>\n",
       "      <th>q2_num_words</th>\n",
       "      <th>word_common</th>\n",
       "      <th>word_total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>56</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035763</td>\n",
       "      <td>-0.026057</td>\n",
       "      <td>-0.736660</td>\n",
       "      <td>-0.683210</td>\n",
       "      <td>-1.207437</td>\n",
       "      <td>0.007205</td>\n",
       "      <td>0.439778</td>\n",
       "      <td>1.143392</td>\n",
       "      <td>-0.321914</td>\n",
       "      <td>0.357581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>87</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076185</td>\n",
       "      <td>-0.265482</td>\n",
       "      <td>-0.010593</td>\n",
       "      <td>-0.600925</td>\n",
       "      <td>-0.332448</td>\n",
       "      <td>-0.050004</td>\n",
       "      <td>-0.049604</td>\n",
       "      <td>-0.333075</td>\n",
       "      <td>-0.262157</td>\n",
       "      <td>0.240166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>58</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224589</td>\n",
       "      <td>-0.276327</td>\n",
       "      <td>-0.583229</td>\n",
       "      <td>0.320713</td>\n",
       "      <td>-0.215515</td>\n",
       "      <td>-0.027906</td>\n",
       "      <td>-0.188592</td>\n",
       "      <td>-0.485715</td>\n",
       "      <td>0.098218</td>\n",
       "      <td>0.272586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>58</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.663913</td>\n",
       "      <td>0.370865</td>\n",
       "      <td>0.569683</td>\n",
       "      <td>0.335602</td>\n",
       "      <td>0.048524</td>\n",
       "      <td>-0.094308</td>\n",
       "      <td>-0.099330</td>\n",
       "      <td>-0.087284</td>\n",
       "      <td>-0.870908</td>\n",
       "      <td>0.420239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093780</td>\n",
       "      <td>-0.636817</td>\n",
       "      <td>0.121273</td>\n",
       "      <td>-0.795181</td>\n",
       "      <td>-0.737698</td>\n",
       "      <td>-0.060013</td>\n",
       "      <td>0.468403</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.301767</td>\n",
       "      <td>0.420947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 623 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_duplicate  q1_len  q2_len  q1_num_words  q2_num_words  word_common  \\\n",
       "0             0      65      56            14            12           11   \n",
       "1             0      50      87            12            17            8   \n",
       "2             0      72      58            14            10            4   \n",
       "3             0      49      58            12            16            1   \n",
       "4             0      75      38            15             7            4   \n",
       "\n",
       "   word_total  word_share   cwc_min   cwc_max  ...       290       291  \\\n",
       "0          23        0.48  0.999980  0.833319  ... -0.035763 -0.026057   \n",
       "1          26        0.31  0.799984  0.399996  ... -0.076185 -0.265482   \n",
       "2          24        0.17  0.399992  0.333328  ... -0.224589 -0.276327   \n",
       "3          22        0.05  0.000000  0.000000  ...  0.663913  0.370865   \n",
       "4          21        0.19  0.399992  0.199998  ... -0.093780 -0.636817   \n",
       "\n",
       "        292       293       294       295       296       297       298  \\\n",
       "0 -0.736660 -0.683210 -1.207437  0.007205  0.439778  1.143392 -0.321914   \n",
       "1 -0.010593 -0.600925 -0.332448 -0.050004 -0.049604 -0.333075 -0.262157   \n",
       "2 -0.583229  0.320713 -0.215515 -0.027906 -0.188592 -0.485715  0.098218   \n",
       "3  0.569683  0.335602  0.048524 -0.094308 -0.099330 -0.087284 -0.870908   \n",
       "4  0.121273 -0.795181 -0.737698 -0.060013  0.468403  0.000519  0.301767   \n",
       "\n",
       "        299  \n",
       "0  0.357581  \n",
       "1  0.240166  \n",
       "2  0.272586  \n",
       "3  0.420239  \n",
       "4  0.420947  \n",
       "\n",
       "[5 rows x 623 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.concat([final_df, temp_df], axis=1)\n",
    "print(final_df.shape)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(final_df.iloc[:,1:].values,final_df.iloc[:,0].values,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.832731455143585"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "rf = RandomForestClassifier(n_jobs=-1,criterion=\"log_loss\")\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45463,  5616],\n",
       "       [ 7909, 21870]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# for random forest model\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.820586707561404"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train,y_train)\n",
    "y_pred1 = xgb.predict(X_test)\n",
    "accuracy_score(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43972,  7107],\n",
       "       [ 7400, 22379]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for xgboost model\n",
    "confusion_matrix(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess2(text):\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = 'Where is the capital of India?'\n",
    "q2 = 'Which city serves as the capital of India?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for word2vec, if word not in word2vec model, there will be key error, so first check if\n",
    "#token is there in word2vec if yes then append else pass np.zeros\n",
    "def vectorize_question_pair(q1, q2, model, size=300):\n",
    "\n",
    "    q1_tokens = preprocess2(q1)\n",
    "    q2_tokens = preprocess2(q2)\n",
    "\n",
    "    def tokens_to_vec(tokens):\n",
    "\n",
    "        vecs = []\n",
    "\n",
    "        for w in tokens:\n",
    "            if w in model.wv:          # ✅ check first\n",
    "                vecs.append(model.wv[w])\n",
    "\n",
    "        if len(vecs) == 0:\n",
    "            return np.zeros(size)\n",
    "\n",
    "        return np.mean(vecs, axis=0)\n",
    "\n",
    "    q1_vec = tokens_to_vec(q1_tokens)\n",
    "    q2_vec = tokens_to_vec(q2_tokens)\n",
    "\n",
    "    return q1_vec, q2_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_common_words(q1,q2):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), q1.split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), q2.split(\" \")))    \n",
    "    return len(w1 & w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_total_words(q1,q2):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), q1.split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), q2.split(\" \")))    \n",
    "    return (len(w1) + len(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fetch_token_features(q1,q2):\n",
    "    \n",
    "    SAFE_DIV = 0.0001 \n",
    "\n",
    "    STOP_WORDS = stopwords.words(\"english\")\n",
    "    \n",
    "    token_features = [0.0]*8\n",
    "    \n",
    "    # Converting the Sentence into Tokens: \n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "    \n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return token_features\n",
    "\n",
    "    # Get the non-stopwords in Questions\n",
    "    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n",
    "    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n",
    "    \n",
    "    #Get the stopwords in Questions\n",
    "    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n",
    "    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n",
    "    \n",
    "    # Get the common non-stopwords from Question pair\n",
    "    common_word_count = len(q1_words.intersection(q2_words))\n",
    "    \n",
    "    # Get the common stopwords from Question pair\n",
    "    common_stop_count = len(q1_stops.intersection(q2_stops))\n",
    "    \n",
    "    # Get the common Tokens from Question pair\n",
    "    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
    "    \n",
    "    \n",
    "    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    \n",
    "    # Last word of both question is same or not\n",
    "    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
    "    \n",
    "    # First word of both question is same or not\n",
    "    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n",
    "    \n",
    "    return token_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fetch_length_features(q1,q2):\n",
    "    \n",
    "    length_features = [0.0]*3\n",
    "    \n",
    "    # Converting the Sentence into Tokens: \n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "    \n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return length_features\n",
    "    \n",
    "    # Absolute length features\n",
    "    length_features[0] = abs(len(q1_tokens) - len(q2_tokens))\n",
    "    \n",
    "    #Average Token Length of both Questions\n",
    "    length_features[1] = (len(q1_tokens) + len(q2_tokens))/2\n",
    "    \n",
    "    strs = list(distance.lcsubstrings(q1, q2))\n",
    "    if len(strs) > 0:\n",
    "        length_features[2] = len(strs[0]) / (min(len(q1), len(q2)) + 1)\n",
    "    else:\n",
    "        length_features[2] = 0.0 # Handle cases where no common substring is found\n",
    "    \n",
    "    return length_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fetch_fuzzy_features(q1,q2):\n",
    "    \n",
    "    fuzzy_features = [0.0]*4\n",
    "    \n",
    "    # fuzz_ratio\n",
    "    fuzzy_features[0] = fuzz.QRatio(q1, q2)\n",
    "\n",
    "    # fuzz_partial_ratio\n",
    "    fuzzy_features[1] = fuzz.partial_ratio(q1, q2)\n",
    "\n",
    "    # token_sort_ratio\n",
    "    fuzzy_features[2] = fuzz.token_sort_ratio(q1, q2)\n",
    "\n",
    "    # token_set_ratio\n",
    "    fuzzy_features[3] = fuzz.token_set_ratio(q1, q2)\n",
    "\n",
    "    return fuzzy_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_point_creator(q1,q2):\n",
    "    \n",
    "    input_query = []\n",
    "    \n",
    "    # preprocess\n",
    "    q1 = preprocess(q1)\n",
    "    q2 = preprocess(q2)\n",
    "    \n",
    "    # fetch basic features\n",
    "    input_query.append(len(q1))\n",
    "    input_query.append(len(q2))\n",
    "    \n",
    "    input_query.append(len(q1.split(\" \")))\n",
    "    input_query.append(len(q2.split(\" \")))\n",
    "    \n",
    "    input_query.append(test_common_words(q1,q2))\n",
    "    input_query.append(test_total_words(q1,q2))\n",
    "    input_query.append(round(test_common_words(q1,q2)/test_total_words(q1,q2),2))\n",
    "    \n",
    "    # fetch token features\n",
    "    token_features = test_fetch_token_features(q1,q2)\n",
    "    input_query.extend(token_features)\n",
    "    \n",
    "    # fetch length based features\n",
    "    length_features = test_fetch_length_features(q1,q2)\n",
    "    input_query.extend(length_features)\n",
    "    \n",
    "    # fetch fuzzy features\n",
    "    fuzzy_features = test_fetch_fuzzy_features(q1,q2)\n",
    "    input_query.extend(fuzzy_features)\n",
    "    \n",
    "    # fasttext feature vectors for q1 and q2\n",
    "    q1_word2vec, q2_word2vec=vectorize_question_pair(q1,q2,modelword2vec,300)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return np.hstack((np.array(input_query).reshape(1,22),q1_word2vec.reshape(1,300),q2_word2vec.reshape(1,300)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3 = 'Where is the capital of India?'\n",
    "q4 = 'what is the step by step guide to invest in share market in india'\n",
    "q5 = 'Which city serves as the capital of India?'\n",
    "q6 = 'What is the business capital of India?'\n",
    "q7= 'what is the step by step guide to invest in share market'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(query_point_creator(q4,q7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x1a4007cbcb0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelword2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelword2vec.save(\"my_modelword2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(rf,open('my_rf_model.pkl','wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
